<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Algorithm,LTR," />





  <link rel="alternate" href="/atom.xml" title="Just Let It Be" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="LTR 算法通常有三种手段，分别是：Pointwise、Pairwise 和 Listwise。Pointwise 和 Pairwise 类型的LTR算法，将排序问题转化为回归、分类或者有序分类问题。Listwise 类型的 LTR 算法则另辟蹊径，将用户查询（Query）所得的结果作为整体，作为训练用的实例（Instance）。">
<meta name="keywords" content="Algorithm,LTR">
<meta property="og:type" content="article">
<meta property="og:title" content="Ltr From Ranknet To Lambdarank To Lambdamart">
<meta property="og:url" content="https://zqg.github.io/2017/02/07/LTR-From-RankNet-to-LambdaRank-to-LambdaMART/index.html">
<meta property="og:site_name" content="Just Let It Be">
<meta property="og:description" content="LTR 算法通常有三种手段，分别是：Pointwise、Pairwise 和 Listwise。Pointwise 和 Pairwise 类型的LTR算法，将排序问题转化为回归、分类或者有序分类问题。Listwise 类型的 LTR 算法则另辟蹊径，将用户查询（Query）所得的结果作为整体，作为训练用的实例（Instance）。">
<meta property="og:image" content="https://zqg.github.io/images/ltr01.png">
<meta property="og:image" content="https://zqg.github.io/images/ltr02.png">
<meta property="og:image" content="https://zqg.github.io/images/ltr03.png">
<meta property="og:image" content="https://zqg.github.io/images/ltr04.png">
<meta property="og:updated_time" content="2017-04-08T10:14:47.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ltr From Ranknet To Lambdarank To Lambdamart">
<meta name="twitter:description" content="LTR 算法通常有三种手段，分别是：Pointwise、Pairwise 和 Listwise。Pointwise 和 Pairwise 类型的LTR算法，将排序问题转化为回归、分类或者有序分类问题。Listwise 类型的 LTR 算法则另辟蹊径，将用户查询（Query）所得的结果作为整体，作为训练用的实例（Instance）。">
<meta name="twitter:image" content="https://zqg.github.io/images/ltr01.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":true,"scrollpercent":true},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zqg.github.io/2017/02/07/LTR-From-RankNet-to-LambdaRank-to-LambdaMART/"/>





  <title> Ltr From Ranknet To Lambdarank To Lambdamart | Just Let It Be </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Just Let It Be</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://zqg.github.io/2017/02/07/LTR-From-RankNet-to-LambdaRank-to-LambdaMART/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Quangang Zheng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Just Let It Be">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Ltr From Ranknet To Lambdarank To Lambdamart
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-02-07T17:25:38+08:00">
                2017-02-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>LTR 算法通常有三种手段，分别是：Pointwise、Pairwise 和 Listwise。Pointwise 和 Pairwise 类型的LTR算法，将排序问题转化为回归、分类或者有序分类问题。Listwise 类型的 LTR 算法则另辟蹊径，将用户查询（Query）所得的结果作为整体，作为训练用的实例（Instance）。</p>
</blockquote>
<a id="more"></a>
<h2 id="Pointwise"><a href="#Pointwise" class="headerlink" title="Pointwise"></a>Pointwise</h2><p>Pointwis方法的主要思想是将排序问题转化为多类分类问题或者回归问题。假设对于查询query，与其相关的文档集合为：{d1, d2, …, dn}。那么:</p>
<ul>
<li><p>多类分类：将query与di之间的相关度的程度作为label，一般的label等级划分方式为：｛Perfect, Excellent, Good, Fair, Bad｝一共五个类别。于是，对于一个查询及其文档集，可以形成n个训练实例。有了训练实例，我们可以使用任一种多类分类器进行学习，比如最大熵、SVM。</p>
</li>
<li><p>回归：将query与di之间的相关度作为value，利用regression model来得到一个query与document之间相关度的预测。</p>
</li>
</ul>
<p>缺点： Pointwise完全从单文档的分类角度计算，没有考虑文档之间的相对顺序。而且它假设相关度是查询无关的，只要（query，di）的相关度相同，那么他们就被划分到同一个级别中，属于同一类。然而实际上，相关度的相对性是和查询相关的，比如一个常见的查询它会有很多相关的文档，该查询和它相关性相对靠后的文档的label标注级别时可能会比一个稀有的查询和它为数不多的高度相关文档的label标准级别更高。这样就导致训练样本的不一致，并且对于预测为同一label级别的文档之间也无法相对排序。</p>
<h2 id="Pairwise"><a href="#Pairwise" class="headerlink" title="Pairwise"></a>Pairwise</h2><p>Pairwise方法是目前比较流行的方法，效果也非常不错。它的主要思想是将Ranking问题形式化为二元分类问题。常用的机器学习的方法比较多，比如Boost、SVM、神经网络等。</p>
<ul>
<li><p>对于同一query的相关文档集中，对任何两个不同label的文档，都可以得到一个训练实例（di,dj），如果di&gt;dj则赋值+1，反之-1，于是我们就得到了二元分类器训练所需的训练样本了，如下图所示。</p>
</li>
<li><p>测试时，只要对所有pair进行分类就可以得到所有文档的一个偏序关系，从而实现排序。</p>
<p><img src="/images/ltr01.png" alt="Pairwise"></p>
</li>
</ul>
<p><strong>缺点</strong> ： 尽管Pairwise对Pointwise做了改进，但该方法还是存在明显的问题</p>
<ol>
<li>只考虑了两篇文档的相对顺序，没有考虑他们出现在搜索结果列表中的位置。排在前面的文档更为重要，如果出现在前面的文档判断错误，惩罚函数要明显高于排在后面判断错误。因此需要引入位置因素，每个文档对根据其在结果列表中的位置具有不同的权重，越排在前面权重越大，如果排错顺序其受到的惩罚也越大。</li>
<li>对于不同的查询相关文档集的数量差异很大，转换为文档对后，有的查询可能只有十几个文档对，而有的查询可能会有数百个对应的文档对，这对学习系统的效果评价带来了偏置。假设查询1对应500个文档对，查询2对应10个文档对，假设机器学习系统对应查询1能够判断正确480个文档对，对应查询2能够判断正确2个。对于总的文档对该系统准确率是（480+2）/（500+10）=95%，但从查询的角度，两个查询对应的准确率分别为：96%和20%，平均为58%，与总的文档对判断准确率相差巨大，这将使得模型偏向于相关文档集大的查询。<br>Pairwise有很多的实现，比如Ranking SVM，RankNet，Frank，RankBoost等。</li>
</ol>
<h2 id="Listwise"><a href="#Listwise" class="headerlink" title="Listwise"></a>Listwise</h2><p>Listwise与上述两种方法不同，它是将每个查询对应的所有搜索结果列表作为一个训练样例。Listwise根据训练样例训练得到最优评分函数F，对应新的查询，评分F对每个文档打分，然后根据得分由高到低排序，即为最终的排序结果。<br>目前主要有两种优化方法：</p>
<ul>
<li>直接针对Ranking评价指标进行优化。比如常用的MAP, NDCG（下面介绍）。这个想法非常自然，但是往往难以实现，因为<a href="https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision" target="_blank" rel="external">MAP</a>、<a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain" target="_blank" rel="external">NDCG</a>这样的评价指标通常是非平滑（连续）的，而通用的目标函数优化方法针对的都是连续函数。</li>
<li>优化损失函数 <strong>loss function</strong>。比如LambdaRank、LambdaMART。</li>
</ul>
<hr>
<h2 id="From-RankNet-to-LambdaRank-to-LambdaMART"><a href="#From-RankNet-to-LambdaRank-to-LambdaMART" class="headerlink" title="From RankNet to LambdaRank to LambdaMART"></a>From RankNet to LambdaRank to LambdaMART</h2><p>LambdaMART 是一种 Listwise 类型的 LTR 算法，它基于 LambdaRank 算法和 MART (Multiple Additive Regression Tree) 算法，将搜索引擎结果排序问题转化为回归决策树问题。MART 实际就是梯度提升决策树（GBDT, Gradient Boosting Decision Tree）算法。GBDT 的核心思想是在不断的迭代中，新一轮迭代产生的回归决策树模型拟合损失函数的梯度，最终将所有的回归决策树叠加得到最终的模型。LambdaMART 使用一个特殊的 Lambda 值来代替上述梯度，也就是将 LambdaRank 算法与 MART 算法加和起来。<br>考虑到 LambdaRank 是基于 RankNet 算法的，所以在搞清楚 LambdaMART 算法之前，我们首先需要了解 MART、RankNet 和 LambdaRank 是怎么回事。</p>
<h3 id="RankNet"><a href="#RankNet" class="headerlink" title="RankNet"></a>RankNet</h3><p>RankNet是2005年微软提出的一种pairwise的Learning to rank算法，它从概率的角度来解决排序问题。RankNet提出了一种概率损失函数来学习Ranking Function，并应用Ranking Function对文档进行排序。这里的Ranking Function可以是任意对参数可导的模型，也就是说，该概率损失函数并不依赖于特定的机器学习模型，在论文中，RankNet是基于神经网络实现的。除此之外，GDBT等模型也可以应用于该框架。  </p>
<h4 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h4><p>变量定义：<br>映射函数：$f(x_i)$</p>
<p>样本i的估计值：$s_i = f(x_i)$</p>
<p>样本ij的差值：$s_{ij} = f(x_i)-f(x_j)$</p>
<p>目标差值：$S_{ij} \in \{-1,0,1\}$  # 1表示样本i排在j之前，0表示相同，-1表示j在前</p>
<p>对同一query的两个样本，经过预测得到两个分值$s_i s_j$，然后将他们映射成概率：</p>
<p>i排序在j之前的目标概率：$\\\\overline{P}_{ij} = \frac{1}{2}(1+S_{ij}) \in \{0, 0.5, 1\}$</p>
<p>i排序在j之前的估计概率：$P_{ij}=\frac{1}{1+e^{-\sigma (s_i-s_j)}},\sigma$决定sigmoid形状，对最终结果影响不大。</p>
<p>交叉熵损失函数：$C_{ij}$</p>
<p>$$<br>C_{ij} = C(s_{ij}) = -\overline{P}_{ij}logP_{ij}-(1-\overline{P}_{ij})log(1-P_{j})<br>$$</p>
<p>$$<br>\Rightarrow C_{ij}=\frac{1}{2}(1-S_{ij})\sigma(s_i-s_j)+ log(1+e^{-\sigma s_{ij}})<br>$$</p>
<p>由$C_{ij}$公式我们可以得出 ，当 $\overline{P}_{ij}=0.5$时，$C_{ij}$是以y轴对称的抛物线函数。</p>
<p><img src="/images/ltr02.png" alt=""></p>
<h4 id="Learning-to-rank-with-two-layer-Nerual-Nets"><a href="#Learning-to-rank-with-two-layer-Nerual-Nets" class="headerlink" title="Learning to rank with two-layer Nerual Nets"></a>Learning to rank with two-layer Nerual Nets</h4><ol>
<li><p>两层神经网络梯度推导：</p>
<p>$$<br>s_i = g^3(\sum_jw_{ij}^{32}g^2(\sum_kw_{jk}^{21}x_k+b_j^2)+b_i^3) = g_i^3<br>$$</p>
<p>$$<br>\Rightarrow \frac{\partial{f}}{\partial{b_i^3}} =\frac{\partial{f}}{\partial{s_i}}g_i^{\prime3}=\Delta_i^3<br>$$</p>
<p>$$<br>\Rightarrow \frac{\partial{f}}{\partial{w_{in}^{32}}} =\frac{\partial{f}}{\partial{s_i}}g_i^{\prime3}g_n^2=\Delta_i^3g_n^2<br>$$</p>
<p>$$<br>\Rightarrow \frac{\partial{f}}{\partial{b_m^2}} =(\sum_i\frac{\partial{f}}{\partial{s_i}}g_i^{\prime3}w_{im^{32}})g_m^{\prime2}=\Delta_m^2<br>$$</p>
<p>$$<br>   \Rightarrow \frac{\partial{f}}{\partial{w_{mn}^{21}}} =x_n\Delta_m^2<br>$$</p>
</li>
<li><p>RankNet中输出节点只有一个，即$i==0$。损失函数变成两个样本输出值的函数$f(s_2-s_1)$。</p>
<p>$$<br>\frac{\partial{f}}{\partial{b^3}}=(\frac{\partial{s_2}}{\partial{\alpha}} - \frac{\partial{s_1}}{\partial{\alpha}})f^{\prime}<br>$$</p>
<p>$$<br>   \Rightarrow \frac{\partial{f}}{\partial{b^3}} =f^{\prime}(g_2^{\prime{3}}-g_1^{\prime3})=\Delta_2^3-\Delta_1^3<br>$$</p>
<p>$$<br>   \Rightarrow \frac{\partial{f}}{\partial{w_{n}^{32}}} =\Delta_2^3g_{2n}^2- \Delta_1^3g_{1n}^2<br>$$</p>
<p>$$<br>   \Rightarrow \frac{\partial{f}}{\partial{b_m^2}} =\Delta_2^3w_m^{32}g_{2m}^{\prime2} - \Delta_1^3w_m^{32}g_{1m}^{\prime2}<br>$$</p>
<p>$$<br>   \Rightarrow \frac{\partial{f}}{\partial{w_{mn}^{21}}} =\Delta_{2m}^2g_{2n}^1 - \Delta_{1m}^2g_{1n}^1<br>$$</p>
</li>
</ol>
<h4 id="一般的梯度下降法推导"><a href="#一般的梯度下降法推导" class="headerlink" title="一般的梯度下降法推导"></a>一般的梯度下降法推导</h4><p>用梯度下降法求解是RankNet的关键思想，不仅可以用神经网络模型，GBDT也可以（xgboost、LightGBM），只不过是需要将$\frac{\partial C}{\partial w_k}$的求解，变成$\frac{\partial C}{\partial s_i}$。下面讲一下一般的梯度下降法的推导。</p>
<p>$$<br>w_k\rightarrow w_k-\eta \frac{\partial C}{\partial w_k}<br>$$</p>
<p>$\eta$为步长，损失函数的改变：</p>
<p>$$<br>\Delta C=\sum_k \frac{\partial C}{\partial w_k}\Delta w_k=\sum_k \frac{\partial C}{\partial w_k}(-\eta \frac{\partial C}{\partial w_k})=-\eta \sum_k (\frac{\partial C}{\partial w_k})^2 &lt; 0<br>$$</p>
<p>损失函数C是逐步减小的，我们继续拆分：</p>
<p>$$<br>\frac{\partial C}{\partial s_i} = \sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-_j)}})=-\frac{\partial C}{\partial s_j}<br>$$</p>
<p>$$<br>\frac{\partial C}{\partial w_k}=\frac{\partial C}{\partial s_i}\frac{\partial s_i}{\partial w_k}+\frac{\partial C}{\partial s_j}\frac{\partial s_j}{\partial w_k}=\sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-_j)}})(\frac{\partial s_i}{\partial w_k} -\frac{\partial s_j}{\partial w_k})<br>$$</p>
<h4 id="RankNet训练加速"><a href="#RankNet训练加速" class="headerlink" title="RankNet训练加速"></a>RankNet训练加速</h4><p>上面的学习过程中，对每一个样本对ij就要做一次参数更新，效率不是很高，比如采用BP神经网络模型，训练会非常慢。下面讲解一下mini-batch的方式更新w，这也是LambdaRank的基础。<br>我们先定义 $\lambda$：</p>
<p>$$<br>\lambda_{ij} = \sigma (\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma (s_i-_j)}})=\frac{\partial C}{\partial s_i}<br>$$</p>
<p>$$<br>\Rightarrow \frac{\partial C}{\partial w_k}=\lambda_{ij} (\frac{\partial s_i}{\partial w_k} -\frac{\partial s_j}{\partial w_k})<br>$$</p>
<p>我们选取一个样本对集合$I$，为了使每个样本对$(i,j)$（$ij$必须属于同一个query）在集合中只出现一次，我们规定$(i,j)$中i要排在j之前，及$S_{ij}=1$。于是我们将$w_k$的更新值变成累加的形式：</p>
<p>$$<br>\Delta w_k=-\eta \sum_{i,j\in I}(\lambda_{ij}\frac{\partial{s_i}}{\partial{w_k}} - \lambda_{ij}\frac{\partial{s_j}}{\partial{w_k}})<br>= -\eta \sum_{i}(\sum_{i&gt;j}\lambda_{ij}\frac{\partial{s_i}}{\partial{w_k}} - \sum_{k&gt;i} \lambda_{k,i}\frac{\partial{s_i}}{\partial{w_k}})<br>=-\eta \sum_{i}\lambda_{i}\frac{\partial{s_i}}{\partial{w_k}}<br>$$</p>
<p>其中$\lambda_i$定义如下：</p>
<blockquote>
<p>对样本i，我们找出所有排在它之前的样本组成$k,i\in I$，然后找到所有排在其后的样本组成$i,j\in I$。</p>
</blockquote>
<p>$$\lambda_i = \sum_{i,j \in I} \lambda_{i,j} - \sum_{k,i\in I} \lambda_{k,i}$$</p>
<p>经过上面的推导，就可以用mini-batch的方式更新$w$权重了。</p>
<h3 id="LambdaRank"><a href="#LambdaRank" class="headerlink" title="LambdaRank"></a>LambdaRank</h3><p>上面介绍的RankNet是以error pair最少为优化目标，然而许多时候仅以error pair数来评价排序的好坏是不够的，因为它只关心pair的相对位置，不关心top K的结果，而IR排序中top K的结果是很重要的，以下图为例：</p>
<p><img src="/images/ltr03.png" alt=""></p>
<p>图中每一条短横线表示一个URL，蓝色表示与Query相关的URL，灰色表示不相关的URL。下面我们用error pair和NDCG分别来评估左右两个排序的好坏：</p>
<ul>
<li>Error pair指标<br>对于排序1，排序错误的pair共13对，故cost=13。<br>对于排序2，排序错误的pair共11对，故cost=11。</li>
</ul>
<p>所以，从Error pair角度考虑，排序2要优于排序1</p>
<ul>
<li>NDCG指标<br>假设相关url分值为1，不相关为0。<br>排序1与排序2具有相同的maxDCG@16,<br>$maxDCG@16=\frac{1}{log(1+1)} + \frac{1}{log(1+2)}=1.63$<br>对排序1，有<br>$DCG@16=\frac{1}{log(1+1)}+\frac{1}{log(1+15)}=1.25$<br>$NDCG@16=1.25/1.63=0.767$<br>对排序2，有<br>$DCG@16=\frac{1}{log(1+4)}+\frac{1}{log(1+10)}=0.72$<br>$NDCG@16=0.72/1.63=0.442$</li>
</ul>
<p>所以，从NDCG指标来看，排序1要优于排序2。</p>
<p>从上面的计算可以看出，用error pair评估的结果有时不是我们期望的。与error pair不同，NDCG评估会强调top K的结果，这是符合我们预期的。而且，排序2中右侧的黑色箭头表示RankNet下一步梯度更新方向，长短表示强度。然而我们真正希望的是红色箭头的形式，排在前面的更新权重更大。</p>
<p>那我们可不可以用RankNet的思路优化像NDCG这样的不平滑、不连续的指标呢？答案是肯定的。LambdaRank的一个关键思想是，我们没有必要构建cost function本身，我们只需要知道梯度就可以了。所以LambdaRank算法分析排序问题，然后直接对RankNet里的$\lambda_{ij}$进行了修改。</p>
<p>$$<br>\lambda_{ij}=\frac{-\sigma}{1+e^{\sigma (s_i-s_j)}}|\Delta Z_{ij}|<br>$$</p>
<p>式中$\Delta Z_{ij}$表示，将$i$和$j$交换位置后，待优化指标的变化，如$\Delta NDCG$就表示将$i$和$j$进行交换（其他url保持不变），交换后排序的NDCG与交换前排序的NDCG的差值。乘积前半部分代表了文档下一次迭代优化的方向和强度，由于引入了IR评价指标，Lambda梯度更关注位置靠前的高匹配度url的排序位置的提升。我们把改进后的算法称之为LambdaRank。</p>
<p>现在我们的优化目标不再是损失函数$C$最小，而是评估指标最大。所以权重更新方程变成：</p>
<p>$$<br>w_k\rightarrow w_k+\eta \frac{\partial C}{\partial w_k}<br>$$</p>
<p>$$<br>\Delta C=\frac{\partial C}{\partial w_k}\Delta w_k=\eta \sum_k (\frac{\partial C}{\partial w_k})^2 &gt; 0<br>$$</p>
<p>LambdaRank相比RankNet的优势在于考虑了评价指标，直接对问题求解，所以效果更好。有效的避免了下调相关度高的url的位置这种情况的发生。</p>
<h3 id="LambdaMART"><a href="#LambdaMART" class="headerlink" title="LambdaMART"></a>LambdaMART</h3><p>LambdaRank中通过直接定义梯度，解决了引入评估指标带来的不连续的问题。这个Lambda梯度可以应用于任何使用梯度下降法求解的模型。Boosted tree是一种很灵活的模型，将它与Lambda相结合就是微软2009年发表的LambdaMART算法。</p>
<p>在MART（GBDT）中，当采用平方误差损失函数时，每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树，残差的意义如公式：残差 = 真实值 - 预测值 。对于一般的损失函数，Friedman提出用损失函数的负梯度值，作为残差的拟合值。</p>
<p>LambdaMART算法中，这个负梯度就是$\lambda_i$。</p>
<p>$$<br>\lambda_{ij}=\frac{-\sigma |\Delta Z_{ij}|}{1+e^{\sigma (s_i-s_j)}}<br>$$</p>
<p>算法[Algorithm 1]中，Step 1-3 是用现有模型初始化初值。Step 6 计算每篇文档的$\lambda$梯度$y_i$。Step 7 计算每篇文档的二阶导数$w_i$。Step 9 是利用所有文档及它们的残差（$\lambda$）建立回归树。Step 11 是利用牛顿-拉夫森方法计算叶结点的权值。Step 14 是更新每篇文档的分数。</p>
<p><img src="/images/ltr04.png" alt="1"></p>
<h3 id="公开的数据集可以使用"><a href="#公开的数据集可以使用" class="headerlink" title="公开的数据集可以使用"></a>公开的数据集可以使用</h3><ul>
<li><a href="http://research.microsoft.com/en-us/um/beijing/projects/letor/" target="_blank" rel="external">LETOR</a></li>
<li><a href="http://research.microsoft.com/en-us/projects/mslr/" target="_blank" rel="external">Microsoft Learning to Rank Dataset</a></li>
<li><a href="http://webscope.sandbox.yahoo.com/" target="_blank" rel="external">Yahoo Learning to Rank Challenge</a></li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Algorithm/" rel="tag"># Algorithm</a>
          
            <a href="/tags/LTR/" rel="tag"># LTR</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/04/07/Hexo-搭建githubpage记录/" rel="next" title="Hexo 搭建github pages记录">
                <i class="fa fa-chevron-left"></i> Hexo 搭建github pages记录
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/12/06/Introduction-to-XGBoost/" rel="prev" title="Introduction to XGBoost">
                Introduction to XGBoost <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
    <div id="hypercomments_widget"></div>
    <script type="text/javascript">
    _hcwp = window._hcwp || [];
    _hcwp.push({widget:"Stream", widget_id: 89339});
    (function() {
    if("HC_LOAD_INIT" in window)return;
    HC_LOAD_INIT = true;
    var lang = (navigator.language || navigator.systemLanguage || navigator.userLanguage || "en").substr(0, 2).toLowerCase();
    var hcc = document.createElement("script"); hcc.type = "text/javascript"; hcc.async = true;
    hcc.src = ("https:" == document.location.protocol ? "https" : "http")+"://w.hypercomments.com/widget/hc/89339/"+lang+"/widget.js";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hcc, s.nextSibling);
    })();
    </script>
    <a href="http://hypercomments.com" class="hc-link" title="comments widget">comments powered by HyperComments</a>
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Quangang Zheng" />
          <p class="site-author-name" itemprop="name">Quangang Zheng</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Pointwise"><span class="nav-number">1.</span> <span class="nav-text">Pointwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pairwise"><span class="nav-number">2.</span> <span class="nav-text">Pairwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Listwise"><span class="nav-number">3.</span> <span class="nav-text">Listwise</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#From-RankNet-to-LambdaRank-to-LambdaMART"><span class="nav-number">4.</span> <span class="nav-text">From RankNet to LambdaRank to LambdaMART</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RankNet"><span class="nav-number">4.1.</span> <span class="nav-text">RankNet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#学习过程"><span class="nav-number">4.1.1.</span> <span class="nav-text">学习过程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Learning-to-rank-with-two-layer-Nerual-Nets"><span class="nav-number">4.1.2.</span> <span class="nav-text">Learning to rank with two-layer Nerual Nets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#一般的梯度下降法推导"><span class="nav-number">4.1.3.</span> <span class="nav-text">一般的梯度下降法推导</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RankNet训练加速"><span class="nav-number">4.1.4.</span> <span class="nav-text">RankNet训练加速</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LambdaRank"><span class="nav-number">4.2.</span> <span class="nav-text">LambdaRank</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LambdaMART"><span class="nav-number">4.3.</span> <span class="nav-text">LambdaMART</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#公开的数据集可以使用"><span class="nav-number">4.4.</span> <span class="nav-text">公开的数据集可以使用</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Quangang Zheng</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  













  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

</body>
</html>
